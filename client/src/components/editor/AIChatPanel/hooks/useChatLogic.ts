/**
 * å¯¹è¯é€»è¾‘ Hook
 */

import type { Editor } from '@tiptap/react'
import { marked } from 'marked'
import { streamChatAPI, executeAIEdit } from '../../../../api/ai'
import type { Message } from '../../../../types/message'
import type { AIEditResponse } from '../../../../types/suggestion'
import type { Outline } from '../../../../types/outline'

// é…ç½® marked é€‰é¡¹
marked.setOptions({
  gfm: true,
  breaks: true,
})

/**
 * æ›´æ–°ç¼–è¾‘å™¨å†…å®¹
 */
function updateEditorContent(editor: Editor | null, markdown: string) {
  if (!editor || editor.isDestroyed || !markdown.trim()) return
  
  try {
    let html = marked.parse(markdown, { async: false }) as string
    html = html.replace(/<li>\s*<p>/g, '<li>')
    html = html.replace(/<\/p>\s*<\/li>/g, '</li>')
    editor.commands.setContent(html)
  } catch (error) {
    console.error('æ›´æ–°ç¼–è¾‘å™¨å†…å®¹å¤±è´¥:', error)
  }
}

interface UseChatLogicParams {
  editor: Editor | null
  documentId: number
  input: string
  model: string
  enableDeepThink: boolean
  generationMode: 'full' | 'outline'
  messages: Message[]
  outline: Outline | null
  addMessage: (message: Message) => void
  updateLastMessage: (updater: (msg: Message) => Message) => void
  generateOutline: (prompt: string, documentId: number, model: string, onReasoning?: (reasoning: string) => void) => Promise<void>
  clearOutline: () => void
  onSuggestionsReceived?: (suggestions: AIEditResponse, isStreaming?: boolean) => { suggestionId?: string } | void
  onStreamingChange?: (isStreaming: boolean) => void
  setInput: (value: string) => void
  setIsThinking: (value: boolean) => void
  setIsGenerating: (value: boolean) => void
  setGeneratedContent: (value: string) => void
  setHasStartedGenerating: (value: boolean) => void
  setGenerationMode: (mode: 'full' | 'outline') => void
  setEnableDeepThink: (enabled: boolean) => void
  setModel: (model: string) => void
}

export function useChatLogic(params: UseChatLogicParams) {
  const {
    editor,
    documentId,
    input,
    model,
    enableDeepThink,
    generationMode,
    messages,
    outline,
    addMessage,
    updateLastMessage,
    generateOutline,
    clearOutline,
    onSuggestionsReceived,
    onStreamingChange,
    setInput,
    setIsThinking,
    setIsGenerating,
    setGeneratedContent,
    setHasStartedGenerating,
  } = params

  const handleSend = async () => {
    console.log('ğŸ“¤ handleSend è¢«è°ƒç”¨')
    
    if (!input.trim() || !editor) {
      console.warn('âš ï¸ handleSend æ¡ä»¶ä¸æ»¡è¶³')
      return
    }

    console.log('âœ… handleSend æ¡ä»¶æ»¡è¶³ï¼Œå¼€å§‹å‘é€æ¶ˆæ¯')

    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: input.trim(),
      timestamp: Date.now(),
    }

    addMessage(userMessage)
    const userInput = input.trim()
    setInput('')
    
    const startTime = Date.now()
    
    // åˆ¤æ–­ç”¨æˆ·æ„å›¾ï¼šæ˜¯ç”Ÿæˆæ–°å†…å®¹è¿˜æ˜¯ç¼–è¾‘ç°æœ‰å†…å®¹
    const currentContent = editor.getText()
    const isEditMode = currentContent.length > 0 && (
      userInput.includes('ä¿®æ”¹') ||
      userInput.includes('æ”¹ä¸º') ||
      userInput.includes('æ”¹æˆ') ||
      userInput.includes('æ›¿æ¢') ||
      userInput.includes('æŠŠ') ||
      userInput.includes('å°†')
    )
    
    // å¦‚æœæ˜¯ç¼–è¾‘æ¨¡å¼ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å…¨æ–‡æ¨¡å¼
    if (isEditMode && generationMode === 'outline') {
      console.log('ğŸ”„ æ£€æµ‹åˆ°ç¼–è¾‘æ„å›¾ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å…¨æ–‡æ¨¡å¼')
      params.setGenerationMode('full')
      params.clearOutline()
    }
    
    // å¦‚æœæ˜¯ç¼–è¾‘æ¨¡å¼ä¸”å¼€å¯äº†æ·±åº¦æ€è€ƒï¼Œè‡ªåŠ¨å…³é—­æ·±åº¦æ€è€ƒ
    // å› ä¸ºç¼–è¾‘æ¨¡å¼ä¼šå¼ºåˆ¶ä½¿ç”¨ chat æ¨¡å‹ï¼Œä¸ä¼šæœ‰æ€è€ƒè¿‡ç¨‹
    if (isEditMode && enableDeepThink) {
      console.log('ğŸ”„ ç¼–è¾‘æ¨¡å¼ä¸æ”¯æŒæ·±åº¦æ€è€ƒï¼Œè‡ªåŠ¨å…³é—­')
      params.setEnableDeepThink(false)
    }
    
    // å¦‚æœæ˜¯ç¼–è¾‘æ¨¡å¼ä¸”å½“å‰æ˜¯ reasoner æ¨¡å‹ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ° chat æ¨¡å‹
    // ä¿æŒ UI æ˜¾ç¤ºä¸å®é™…ä½¿ç”¨çš„æ¨¡å‹ä¸€è‡´
    if (isEditMode && model === 'deepseek-reasoner') {
      console.log('ğŸ”„ ç¼–è¾‘æ¨¡å¼åˆ‡æ¢åˆ° chat æ¨¡å‹')
      params.setModel('deepseek-chat')
    }
    
    // æ ¹æ®æ·±åº¦æ€è€ƒå¼€å…³é€‰æ‹©æ¨¡å‹
    // æ³¨æ„ï¼šåªæœ‰ deepseek-reasoner æ”¯æŒæ·±åº¦æ€è€ƒ
    // å¦‚æœå½“å‰æ¨¡å‹ä¸æ˜¯ reasonerï¼Œæ·±åº¦æ€è€ƒå¼€å…³æ— æ•ˆ
    let selectedModel = model
    if (enableDeepThink && model === 'deepseek-chat') {
      // å¦‚æœå¯ç”¨æ·±åº¦æ€è€ƒä¸”å½“å‰æ˜¯ chat æ¨¡å‹ï¼Œåˆ‡æ¢åˆ° reasoner
      selectedModel = 'deepseek-reasoner'
    } else if (enableDeepThink && model !== 'deepseek-reasoner') {
      // å¦‚æœå¯ç”¨æ·±åº¦æ€è€ƒä½†æ¨¡å‹ä¸æ”¯æŒï¼Œä½¿ç”¨åŸæ¨¡å‹ï¼ˆæ·±åº¦æ€è€ƒæ— æ•ˆï¼‰
      console.warn('âš ï¸ å½“å‰æ¨¡å‹ä¸æ”¯æŒæ·±åº¦æ€è€ƒï¼Œå°†ä½¿ç”¨æ™®é€šæ¨¡å¼')
      selectedModel = model
    } else if (!enableDeepThink && model === 'deepseek-reasoner') {
      // å¦‚æœå…³é—­æ·±åº¦æ€è€ƒä½†å½“å‰æ˜¯ reasoner æ¨¡å‹ï¼Œåˆ‡æ¢åˆ° chat æ¨¡å‹
      // é¿å… reasoner æ¨¡å‹è¾“å‡ºä¸å¿…è¦çš„æ€è€ƒè¿‡ç¨‹
      console.log('ğŸ”„ å…³é—­æ·±åº¦æ€è€ƒï¼Œåˆ‡æ¢åˆ° chat æ¨¡å‹')
      selectedModel = 'deepseek-chat'
    }
    
    // å¦‚æœæ˜¯ç¼–è¾‘æ¨¡å¼ï¼Œä¼˜å…ˆå¤„ç†ç¼–è¾‘é€»è¾‘ï¼Œä¸ç®¡ç”Ÿæˆæ¨¡å¼æ˜¯ä»€ä¹ˆ
    if (isEditMode) {
      console.log('ğŸ”§ ç¼–è¾‘æ¨¡å¼ï¼šä¿®æ”¹ç°æœ‰å†…å®¹')
      
      // ç¼–è¾‘æ¨¡å¼ä¸‹å¼ºåˆ¶ä½¿ç”¨ chat æ¨¡å‹
      // å› ä¸º reasoner æ¨¡å‹åœ¨ç¼–è¾‘ä»»åŠ¡ä¸­å¯èƒ½ä¸è¿”å›æ­£ç¡®çš„ JSON æ ¼å¼
      const editModel = selectedModel.includes('reasoner') ? 'deepseek-chat' : selectedModel
      
      if (selectedModel.includes('reasoner')) {
        console.log('âš ï¸ ç¼–è¾‘æ¨¡å¼ä¸æ”¯æŒ reasoner æ¨¡å‹ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ° chat æ¨¡å‹')
      }
      
      setIsThinking(true)
      setIsGenerating(true)
      setHasStartedGenerating(false)
      onStreamingChange?.(true)

      const aiMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: '',
        reasoning: '',
        timestamp: Date.now(),
        isStreaming: true,
        isGeneratingToEditor: false,
      }
      addMessage(aiMessage)

      let accumulatedContent = ''
      const plainTextContent = editor.getText()

      await executeAIEdit({
        documentContent: plainTextContent,
        userRequest: userInput,
        model: editModel,  // ä½¿ç”¨ chat æ¨¡å‹
        onReasoning: (reasoning) => {
          updateLastMessage(msg => ({
            ...msg,
            reasoning: (msg.reasoning || '') + reasoning
          }))
        },
        onChunk: (chunk) => {
          accumulatedContent += chunk
          if (!params.setHasStartedGenerating && accumulatedContent.trim()) {
            setHasStartedGenerating(true)
          }
        },
        onStructured: (data) => {
          console.log('ğŸ“ æ”¶åˆ°ç»“æ„åŒ–ä¿®æ”¹å»ºè®®')
          setIsThinking(false)
          setHasStartedGenerating(false)
          
          const duration = (Date.now() - startTime) / 1000
          const tokens = Math.ceil((plainTextContent.length + userInput.length + accumulatedContent.length) / 2)
          const cost = tokens * 0.000001
          
          updateLastMessage(msg => ({
            ...msg,
            content: `æ ¹æ®ä½ çš„æè¿°ï¼Œæˆ‘å°†ä¸ºä½ ${data.reasoning || 'ä¿®æ”¹æ–‡æ¡£'}ã€‚\n\nä¿®æ”¹å»ºè®®å·²åœ¨ç¼–è¾‘å™¨ä¸­æ ‡è®°ï¼ˆåˆ é™¤çº¿ + ç»¿è‰²é«˜äº®ï¼‰ï¼Œè¯· hover æŸ¥çœ‹å¹¶é€‰æ‹©æ¥å—æˆ–æ‹’ç»ã€‚`,
            isStreaming: false,
            stats: { duration, tokens, cost }
          }))
          
          if (onSuggestionsReceived) {
            onSuggestionsReceived(data as AIEditResponse, false)
          }
        },
        onComplete: () => {
          setIsThinking(false)
          setIsGenerating(false)
          setHasStartedGenerating(false)
          onStreamingChange?.(false)
          
          updateLastMessage(msg => ({
            ...msg,
            isStreaming: false,
            isGeneratingToEditor: false
          }))
        },
        onError: (error) => {
          setIsThinking(false)
          setIsGenerating(false)
          setHasStartedGenerating(false)
          onStreamingChange?.(false)
          
          console.error('AI ç¼–è¾‘é”™è¯¯:', error)
          updateLastMessage(msg => ({
            ...msg,
            content: 'æŠ±æ­‰ï¼Œå¤„ç†ä½ çš„è¯·æ±‚æ—¶å‡ºé”™äº†ã€‚è¯·é‡è¯•ã€‚',
            isStreaming: false
          }))
        },
      })
      
      return  // ç¼–è¾‘æ¨¡å¼å¤„ç†å®Œæˆï¼Œç›´æ¥è¿”å›
    }
    
    // å¤§çº²æ¨¡å¼ï¼ˆåªåœ¨éç¼–è¾‘æ¨¡å¼ä¸‹æ‰§è¡Œï¼‰
    if (generationMode === 'outline') {
      setIsThinking(true)
      
      const aiMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: '',
        reasoning: '',
        timestamp: Date.now(),
        isStreaming: true,
        isGeneratingToEditor: false,
      }
      addMessage(aiMessage)
      
      try {
        console.log('ğŸ¯ å¼€å§‹ç”Ÿæˆå¤§çº²')
        
        await generateOutline(userInput, documentId, selectedModel, (thinking: string) => {
          updateLastMessage(msg => ({
            ...msg,
            reasoning: (msg.reasoning || '') + thinking
          }))
        })
        
        const duration = (Date.now() - startTime) / 1000
        const tokens = Math.ceil((userInput.length + 500) / 2)
        const cost = tokens * 0.000001
        
        updateLastMessage(msg => ({
          ...msg,
          content: 'å¤§çº²å·²ç”Ÿæˆï¼Œè¯·åœ¨å³ä¾§ç¼–è¾‘åç‚¹å‡»"åŸºäºå¤§çº²ç”Ÿæˆæ–‡æ¡£"æŒ‰é’®ã€‚',
          isStreaming: false,
          stats: { duration, tokens, cost }
        }))
      } catch (error) {
        console.error('ç”Ÿæˆå¤§çº²å¤±è´¥:', error)
        updateLastMessage(msg => ({
          ...msg,
          content: 'æŠ±æ­‰ï¼Œç”Ÿæˆå¤§çº²æ—¶å‡ºé”™äº†ã€‚è¯·é‡è¯•ã€‚',
          isStreaming: false
        }))
      } finally {
        setIsThinking(false)
      }
      
      return
    }
    
    // ç”Ÿæˆæ¨¡å¼ï¼šæ¸…ç©ºç¼–è¾‘å™¨ï¼Œç”Ÿæˆæ–°å†…å®¹
    console.log('âœ¨ ç”Ÿæˆæ¨¡å¼ï¼šåˆ›å»ºæ–°å†…å®¹')
    
    setIsThinking(true)
    setIsGenerating(true)
    setHasStartedGenerating(false)
    onStreamingChange?.(true)
    
    // æ¸…ç©ºç¼–è¾‘å™¨å†…å®¹
    editor.commands.clearContent()
      setGeneratedContent('')

      const aiMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: '',
        reasoning: '',
        timestamp: Date.now(),
        isStreaming: true,
        isGeneratingToEditor: false,
      }
      addMessage(aiMessage)

      let accumulatedContent = ''
      let updateTimer: ReturnType<typeof setTimeout> | null = null
      let lastUpdateTime = 0
      const UPDATE_INTERVAL = 100

      await streamChatAPI({
        messages: [
          ...messages.map(m => ({ role: m.role, content: m.content })),
          { role: 'user', content: userMessage.content },
        ],
        model: selectedModel,
        onReasoning: (reasoning) => {
          updateLastMessage(msg => ({
            ...msg,
            reasoning: (msg.reasoning || '') + reasoning
          }))
        },
        onChunk: (chunk) => {
          accumulatedContent += chunk
          
          if (!params.setHasStartedGenerating && accumulatedContent.trim()) {
            setHasStartedGenerating(true)
            setIsThinking(false)
            
            updateLastMessage(msg => ({
              ...msg,
              isGeneratingToEditor: true
            }))
          }
          
          setGeneratedContent(accumulatedContent)
          
          const now = Date.now()
          if (now - lastUpdateTime >= UPDATE_INTERVAL) {
            lastUpdateTime = now
            updateEditorContent(editor, accumulatedContent)
          } else {
            if (updateTimer) clearTimeout(updateTimer)
            updateTimer = setTimeout(() => {
              updateEditorContent(editor, accumulatedContent)
              lastUpdateTime = Date.now()
            }, UPDATE_INTERVAL)
          }
        },
        onComplete: () => {
          if (updateTimer) clearTimeout(updateTimer)
          updateEditorContent(editor, accumulatedContent)
          
          setIsThinking(false)
          setIsGenerating(false)
          setHasStartedGenerating(false)
          onStreamingChange?.(false)
          
          const duration = (Date.now() - startTime) / 1000
          const tokens = Math.ceil((userInput.length + accumulatedContent.length) / 2)
          const cost = tokens * 0.000001
          
          updateLastMessage(msg => ({
            ...msg,
            isStreaming: false,
            isGeneratingToEditor: false,
            content: accumulatedContent,
            stats: { duration, tokens, cost }
          }))
        },
        onError: (error) => {
          setIsThinking(false)
          setIsGenerating(false)
          setHasStartedGenerating(false)
          onStreamingChange?.(false)
          
          console.error('AI é”™è¯¯:', error)
          updateLastMessage(msg => ({
            ...msg,
            content: 'æŠ±æ­‰ï¼Œç”Ÿæˆå†…å®¹æ—¶å‡ºé”™äº†ã€‚è¯·é‡è¯•ã€‚',
            isStreaming: false
          }))
        },
      })
  }

  const handleStop = () => {
    setIsGenerating(false)
    setIsThinking(false)
    setHasStartedGenerating(false)
    onStreamingChange?.(false)
  }

  const handleUndo = () => {
    if (!editor) return
    editor.commands.clearContent()
    setGeneratedContent('')
    onStreamingChange?.(false)
  }

  const handleGenerateFromOutline = async () => {
    if (!outline || !editor) return

    setIsGenerating(true)
    setIsThinking(true)
    onStreamingChange?.(true)

    const documentModel = model.includes('reasoner') ? 'deepseek-chat' : model

    try {
      const response = await fetch('/api/ai/generate-from-outline', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          documentId,
          outline: outline.nodes,
          originalPrompt: messages.find(m => m.role === 'user')?.content || '',
          model: documentModel,
        }),
      })

      if (!response.ok) throw new Error(`HTTP error! status: ${response.status}`)

      const reader = response.body?.getReader()
      const decoder = new TextDecoder()
      if (!reader) throw new Error('No response body')

      let buffer = ''
      let accumulatedContent = ''
      editor.commands.clearContent()

      while (true) {
        const { done, value } = await reader.read()
        if (done) break

        buffer += decoder.decode(value, { stream: true })
        const lines = buffer.split('\n')
        buffer = lines.pop() || ''

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = JSON.parse(line.slice(6))

            if (data.type === 'content') {
              accumulatedContent += data.data.content || ''
              
              let cleanContent = accumulatedContent
              cleanContent = cleanContent.replace(/^```(?:markdown|md)?\s*\n?/i, '')
              cleanContent = cleanContent.replace(/\n?```\s*$/i, '')
              cleanContent = cleanContent.replace(/^å¥½çš„[ï¼Œ,].*?[ã€‚\.]\s*\n*/i, '')
              cleanContent = cleanContent.replace(/^æ ¹æ®.*?[ï¼Œ,].*?[ï¼š:]\s*\n*/i, '')
              cleanContent = cleanContent.trim()
              
              updateEditorContent(editor, cleanContent)
              setGeneratedContent(cleanContent)
            } else if (data.type === 'error') {
              throw new Error(data.data.error || 'Unknown error')
            }
          }
        }
      }

      clearOutline()
      setIsThinking(false)
      setIsGenerating(false)
      onStreamingChange?.(false)
    } catch (err) {
      const message = err instanceof Error ? err.message : 'Failed to generate document'
      console.error('Document generation error:', err)
      setIsThinking(false)
      setIsGenerating(false)
      onStreamingChange?.(false)
      alert(`ç”Ÿæˆæ–‡æ¡£å¤±è´¥: ${message}`)
    }
  }

  return {
    handleSend,
    handleStop,
    handleUndo,
    handleGenerateFromOutline,
  }
}
